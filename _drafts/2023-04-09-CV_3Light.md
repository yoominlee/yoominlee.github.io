---
layout: post
title: ITE4052_CV > 3_Light 
subtitle: 3_Light
categories: ComputerVision
tags: [ComputerVision, ITE4052]
use_math: true
---

## illumination, brightness
![1][1]
- illumination   
: 실제 픽셀 값(위 이미지의 A와 B 같다고 판단)   
- brightness   
: What we feel(위 이미지의 A와 B 다르다고 판단)

$\because$ 사람은 조명과 물체 decompose 하는 능력 있음.


![2][2]  

## Radiometry
(무엇이 pixel의 brightness 결정하는가)

![3][3]

중요 세가지
1. 조명조건: 색깔 세기 등
2. 환경적인 요소: 물질의 특성, 보는 각도, 물체와 카메라의 특성들, 카메라 자체의 노출과 관련된 특성 등
-> 이 챕터에서는 하나로 모아 $\rho$ (/rho/) 로 표현
3. 센서(사람으로 보면 시신경)에 따라 intensity, 색상 등 결정



## 사람눈에 들어오는 illuminance $ I $ 

물체로부터 받은 light(Illuminance):
$$I(\lambda) = \rho(\lambda) L(\lambda)$$


L(λ):
- 표면의 입사된 빛의 양
- Incident energy distribution 


ρ(λ): Reflectance(albedo)
- 표면에서 반사되는 입사광의 비율. 
- 물체의 반사율, 투과율


![4][4]



## visual system이 light source로부터 받는 에너지 Luminance(or Intensity)
⭐
$$f(x,y) = \int_{0}^{\infin}I(x,y,\lambda)V(\lambda)d\lambda$$

이때 $I(\lambda) = \rho(\lambda) L(\lambda)$

실제 pixel value인 f(x,y)를 구하는 것.   
Illuminance $I$와 얼마나 민감한지 나타내는 $V$ 곱해서 integrity   

> 빛의 세기와 센서 값이 정해져 있으면 luminance 구할 수 있다(?)

$I$: Light distribution received from an object   
$V$: Luminosity function (Relative luminous efficiency function of the visual system)


### Photosensitive Cells
망막 retina에 있는 두 photosensitive cells   
-> rods and cons 이 두가지가 빛을 인지하는 세포.

- Rods(간상체) -> Intensity 
- Cones(추상체) -> Color


![5][5]

두 세포가 다른 sensitivity, range 가짐


### Brightness Contrast and Constancy
: (사람은 luminance로부터 brightness 정하는 한 단계가 더있다.) brightness는 빛 하나만 보는 것이 아닌 주변 surrounding을 같이 본다.

#### brightness contrast
: 같은데 다르게 보는 상황

ex\) 사람은 실제 조명이 무엇인지를 예측하는 부분이 있기 때문에,   
주변이 어두우면 어두운데서 찍었다고 생각해서 물체가 실제보다 어둡게 나왔다고 processing.   
반대로 전체적인 밝기가 bright-> 밝은데서 찍었다 -> 실제 object는 더 어둡겠구나 라고 process.


#### brightness constancy   
: 다른데 같게 보는 상황

ex\) 검은색과 흰색이라도 어두운곳에서 찍은 검은 물체, 
밝은곳에서 찍은 흰색 물체가 있을 때 픽셀값은 다르지만, 실제 오브젝트 색이 뭔지 생각을 하는 보정을 거치면서 둘 같아보이는 경우.


## Brightness / Contrast

### Brightness
: 우리가 실제 감지하는 것   
(주변 luminance에 따른 감지한 luminance)



### Contrast

Weber’s Law: 실제로 빛의 세기에 차이가 느껴지는 정도는 현재의 세기에 정비례한다.

현재 밝기가 충분히 밝은 경우 여기서부터 차이가 느껴지려면 이것보다더 많은 차이가 있어야 차이가 지각된다.



![6][6]
![7][7]

따라서 실제 픽셀의 밝기(그래프의 실선)와 우리가 느끼는 밝기(그래프의 점선)에 차이가 발생한다.


##### Visible light
##### Color



### 3 Types of Cones

![8][8]

빛을 인지하는 세포 중 색상을 인지하는 세포인 Cones에 세 종류 있다. 각각 Red, Green, Blue 인지.

이 셋은 different cones with different sensitivity.

![9][9]

우 상단의 수식에서 $V(\lambda)$ (= 얼마나 민감한지)가 그래프의 각 cone에 해당.

> 사람눈에 RGB센서가 있어 우리가 색 표현 하는데에도 RGB 표현법을 사용한다.   
(3개의 cone이 있는 human visual system과 유사하게)



![10][10]
(i-th cone response)
> notation V -> S, I -> C로 변경

R값 구하기 위해서 $\int_{\lambda_{min}}^{\lambda_{max}} V_{R}I d\lambda$   
G값 구하기 위해서 $\int_{\lambda_{min}}^{\lambda_{max}} V_{G}I d\lambda$   
B값 구하기 위해서 $\int_{\lambda_{min}}^{\lambda_{max}} V_{B}I d\lambda$


Q. 하지만 매번 $S_{i}$(response) 알아야하나? (integration 복잡)   
A. NO! 매번 적분하는 것이 아닌 수식 단순화 하는 법 있음

## Color matching ⭐⭐


<< 이부분 다시 >>



![11][11]





















---
---
---


## Linear Classifier
: <span style = "color:#909090">*선을 이용하여 집단을 두개 이상으로 분류하는 모델*</span>
$$f(x_{i},W,b) = Wx_{i}+b $$

#### matrix size example:

$f(x_{i},W,b)$ : 10 x 1  

$W$ : 10 x 3072  
$x_{i}$ : 3072 x 1   
　　= 32x32x3(이미지 1개) x 1  
$b$ : 10 x 1

#### input, output:

input으로 $x_{i}$ 이미지 넣으면 $\to$ output으로 각 class 별 score인 10개의 수

![1][1]

이러한 classifier가 내놓은 결과값에 대해 평가하기 위해 정답 레이블과 비교.   
이때 비교해주는 함수가 Loss function

## Multiclass SVM Loss (= hinge loss)

$$L_{i} = \begin{Bmatrix}0 　　 (if S_{y_{i}} \geq S_{j} + 1) \\ S_{j} - S_{y_{i}} + 1　(othersise)\\ \end{Bmatrix}$$

$$= \sum_{j\neq y_{i}} max(0, S_{j} - S_{y_{i}} + 1)$$

$S_{j}$  : 오답 카테고리의 score  
$S_{y_{i}}$  : 정답 카테고리의 score

정답 score가 오답score보다 safty margin인 1보다 크면 loss가 0  
즉 좋은 output이라는 것 

그리고 위의 조건이 아니라면, 오답 score - 정답 score + 1을 loss로

<span style = "color:#909090">*결국 얼마나 안좋은지를 나타내는 수치*</span>

그리고 이를 그래프로 나타내면 

![2][2]  


#### 예시\)  
cat, car, frog 이미지를 넣고 이 3가지 class에 대한 score를 가지고 SVM loss 계산

| |고양이 이미지|자동차 이미지|개구리 이미지|
|:---:|:---:|:---:|:---:|
|cat|**3.2**|1.3|2.2|
|car|5.1|**4.9**|2.5|
|frog|-1.7|2.0|**-3.1**|

고양이 이미지를 넣은 경우,  
cat class의 점수가 가장 높아야 하는데 car class의 점수가 가장 높다.  
따라서 loss 가지게 됨.

먼저 cat와 car로 loss 계산을 해보면,  
$S_{j} - S_{y_{i}} + 1$  
= (오답인 car) - (정답인 cat) + 1  
= 5.1 - 3.2 + 1

cat과 frog를 보면,  
cat이 3.2, frog가 -1.7이다.  
cat이 1 이상 크기 때문에 loss가 0

따라서 cat의 loss인 $\sum_{j\neq y_{i}} max(0, S_{j} - S_{y_{i}} + 1)$ 는  
2.9 + 0 이다.

\+ 자동차는 0  
\+ 개구리는 6.3 + 6.6 = 12.9

**각각의 $L_{i}$ 들로 최종 $L$을 구하면,**
$$L = \frac{1}{N} \sum_{i=1}^N L_{i} $$  
$L = (2.9 + 0 + 12.9)/3$
$5.27$


#### hinge loss의 특징
- 데이터에 민감하지 않다. score의 점수보다 정답이 오답보다 높은지가 중점
- 최소 0, 최대 $\infty$
- $W$ 값이 작아 score 자체가 작아지는 경우에도 마지막에 더하는 1이 있어서 0의 근사치가 나오더라도 Loss 자체가 무한히 작아지지 않음 (sanity check)

## Softmax Classifier

#### 계산법

1. softmax 함수를 거쳐 class별 확률을 계산  
    $$P(Y = k | X = x_{i}) = \frac{e^sj}{\sum_{j}e^s j} $$

    <span style = "color:#909090">*모든 스코어 exp 취한것의 합으로 해당 class의 스코어에 exp 한 것을 나눔*</span>  
    <span style = "color:#909090">*= 확률*</span>

    0~1 사이의 값, 모든 확률의 합은 1

2. 이후 확률값과 실제값 비교
    $$L_{i} = - \log {P(Y = y_{i} | X = x_{i})} $$  

    <span style = "color:#909090">*위의 값에 -log 취해주어 loss 구함*</span>

#### 특징
- 정답점수만 높으면 상관없던 hinge loss(점수에 둔감)와 달리  
확률로 계산되기 때문에 데이터 변경되면 값에 영향을 미침.  
따라서 데이터에 민감함

> W 값이 너무 오버피팅 되는 경우 방지하기 위한 Regularization과   
> 최적의 W 찾는 Optimization은 다음 post에




[1]: /assets/images/post_img/2023-04-09-CV_3Light/1.jpg
[2]: /assets/images/post_img/2023-04-09-CV_3Light/2.png
[3]: /assets/images/post_img/2023-04-09-CV_3Light/3.jpg
[4]: /assets/images/post_img/2023-04-09-CV_3Light/4.jpg
[5]: /assets/images/post_img/2023-04-09-CV_3Light/5.jpg

[6]: /assets/images/post_img/2023-04-09-CV_3Light/6.jpg
[7]: /assets/images/post_img/2023-04-09-CV_3Light/7.jpg

[8]: /assets/images/post_img/2023-04-09-CV_3Light/8.jpg
[9]: /assets/images/post_img/2023-04-09-CV_3Light/9.jpg

[10]: /assets/images/post_img/2023-04-09-CV_3Light/10.jpg
[11]: /assets/images/post_img/2023-04-09-CV_3Light/11.jpg

출처1 : 2023-1 ITE4052 수업  






